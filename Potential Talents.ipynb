{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa1f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import jaccard_score\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ecdf7e",
   "metadata": {},
   "source": [
    "# Performing EDA: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a0adedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur_dir = Path().resolve()\n",
    "#print(cur_dir)\n",
    "#path_to_file = Path.joinpath(cur_dir, 'potential_talents_OG.xlsx')\n",
    "#join_path = cur_dir / 'potential_talents_OG.xlsx'\n",
    "#print(\"the joined path =\", join_path)\n",
    "\n",
    "data = pd.read_excel(\"potential_talents_OG.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c02e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                          job_title  \\\n",
      "0      1  2019 C.T. Bauer College of Business Graduate (...   \n",
      "1      2  Native English Teacher at EPIK (English Progra...   \n",
      "2      3              Aspiring Human Resources Professional   \n",
      "3      4             People Development Coordinator at Ryan   \n",
      "4      5    Advisory Board Member at Celal Bayar University   \n",
      "..   ...                                                ...   \n",
      "99   100  Aspiring Human Resources Manager | Graduating ...   \n",
      "100  101              Human Resources Generalist at Loparex   \n",
      "101  102   Business Intelligence and Analytics at Travelers   \n",
      "102  103                     Always set them up for Success   \n",
      "103  104   Director Of Administration at Excellence Logging   \n",
      "\n",
      "                                location connection  fit  \n",
      "0                         Houston, Texas         85  NaN  \n",
      "1                                 Kanada      500+   NaN  \n",
      "2    Raleigh-Durham, North Carolina Area         44  NaN  \n",
      "3                          Denton, Texas      500+   NaN  \n",
      "4                         İzmir, Türkiye      500+   NaN  \n",
      "..                                   ...        ...  ...  \n",
      "99              Cape Girardeau, Missouri        103  NaN  \n",
      "100  Raleigh-Durham, North Carolina Area      500+   NaN  \n",
      "101           Greater New York City Area         49  NaN  \n",
      "102             Greater Los Angeles Area      500+   NaN  \n",
      "103                          Katy, Texas      500+   NaN  \n",
      "\n",
      "[104 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_excel(path_to_file)\n",
    "# print(data)\n",
    "print(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0e6bbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.166206</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  fit\n",
       "count  104.000000  0.0\n",
       "mean    52.500000  NaN\n",
       "std     30.166206  NaN\n",
       "min      1.000000  NaN\n",
       "25%     26.750000  NaN\n",
       "50%     52.500000  NaN\n",
       "75%     78.250000  NaN\n",
       "max    104.000000  NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe() # the stats of the data, mean, mediun, max and min, and std value of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87f26981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape # checking the shape of the data\n",
    "\n",
    "# balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8649664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2019 C.T. Bauer College of Business Graduate (...\n",
       "1      Native English Teacher at EPIK (English Progra...\n",
       "2                  Aspiring Human Resources Professional\n",
       "3                 People Development Coordinator at Ryan\n",
       "4        Advisory Board Member at Celal Bayar University\n",
       "                             ...                        \n",
       "99     Aspiring Human Resources Manager | Graduating ...\n",
       "100                Human Resources Generalist at Loparex\n",
       "101     Business Intelligence and Analytics at Travelers\n",
       "102                       Always set them up for Success\n",
       "103     Director Of Administration at Excellence Logging\n",
       "Name: job_title, Length: 104, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['job_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2470d2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           Houston, Texas\n",
       "1                                   Kanada\n",
       "2      Raleigh-Durham, North Carolina Area\n",
       "3                            Denton, Texas\n",
       "4                           İzmir, Türkiye\n",
       "                      ...                 \n",
       "99                Cape Girardeau, Missouri\n",
       "100    Raleigh-Durham, North Carolina Area\n",
       "101             Greater New York City Area\n",
       "102               Greater Los Angeles Area\n",
       "103                            Katy, Texas\n",
       "Name: location, Length: 104, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5136ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [2019, ct, bauer, colleg, busi, graduat, magna...\n",
      "1      [nativ, english, teacher, epik, english, progr...\n",
      "2                    [aspir, human, resourc, profession]\n",
      "3                        [peopl, develop, coordin, ryan]\n",
      "4       [advisori, board, member, celal, bayar, univers]\n",
      "                             ...                        \n",
      "99     [aspir, human, resourc, manag, graduat, may, 2...\n",
      "100                [human, resourc, generalist, loparex]\n",
      "101                     [busi, intellig, analyt, travel]\n",
      "102                                [alway, set, success]\n",
      "103                    [director, administr, excel, log]\n",
      "Name: job_title, Length: 104, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# seperate job_title and location by removing punctuation \n",
    "\n",
    "# List of column names to remove punctuation from\n",
    "columns_to_clean = ['job_title']\n",
    "\n",
    "# Function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator) if isinstance(text, str) else text\n",
    "\n",
    "# Function to tokenize a string\n",
    "def tokenize(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(text) if isinstance(text, str) else text\n",
    "\n",
    "# Function to remove stop words from a list of tokens\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "# Function to lemmatize a list of tokens\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# Function to stem a list of tokens\n",
    "def stem(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# Call the functions to the specified column\n",
    "for column_name in columns_to_clean:\n",
    "    data[column_name] = data[column_name].apply(remove_punctuation)\n",
    "    data[column_name] = data[column_name].apply(tokenize)\n",
    "    data[column_name] = data[column_name].apply(remove_stopwords)\n",
    "    data[column_name] = data[column_name].apply(lemmatize)\n",
    "    data[column_name] = data[column_name].apply(stem)\n",
    "\n",
    "print(data[column_name])\n",
    "\n",
    "json_data = data.to_json(orient='records')\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = 'tokenized_file.json'\n",
    "\n",
    "# Write the JSON data to a file\n",
    "with open(output_file, 'w') as file:\n",
    "    file.write(json_data)\n",
    "# Save the modified DataFrame to a new Excel file\n",
    "# data.to_excel('tokenized_file.xlsx', index=False) # save it as a json file\n",
    "\n",
    "# read json file then convert it back into a df then take input (also apply all necessary steps for input)   \n",
    "# then apply jaccard similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf1890",
   "metadata": {},
   "source": [
    "To solve the respective error: AttributeError: 'list' object has no attribute 'translate'\n",
    "\n",
    "In this updated code, we added checks to handle non-string values in the columns. The remove_punctuation and tokenize functions now check if the input text is a string before applying the corresponding operations. If the text is not a string (e.g., a list), it is returned as is without attempting to translate or tokenize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e716582",
   "metadata": {},
   "source": [
    "Tokenization: Breaks up the string into a list of words based on a specified pattern using Regular Expressions aka RegEx\n",
    "\n",
    "Lemmatisation: mapping common words into one base.\n",
    "\n",
    "Stemming: It cuts off prefixes and/or endings of words based on common ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e085e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open(output_file, 'r') as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da6692bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type[0      [2019, ct, bauer, colleg, busi, graduat, magna...\n",
      "1      [nativ, english, teacher, epik, english, progr...\n",
      "2                    [aspir, human, resourc, profession]\n",
      "3                        [peopl, develop, coordin, ryan]\n",
      "4       [advisori, board, member, celal, bayar, univers]\n",
      "                             ...                        \n",
      "99     [aspir, human, resourc, manag, graduat, may, 2...\n",
      "100                [human, resourc, generalist, loparex]\n",
      "101                     [busi, intellig, analyt, travel]\n",
      "102                                [alway, set, success]\n",
      "103                    [director, administr, excel, log]\n",
      "Name: job_title, Length: 104, dtype: object]\n"
     ]
    }
   ],
   "source": [
    "df_json = pd.DataFrame(json_data)\n",
    "read_data = pd.read_json('tokenized_file.json')\n",
    "print(type[read_data['job_title']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40745665",
   "metadata": {},
   "source": [
    "### Applying same process as above but with inserting a free text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2231d05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the free text: engineer\n",
      "['engin']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Initialize the PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Insert a free text\n",
    "free_text = input(\"Enter the free text: \")\n",
    "\n",
    "# Tokenize the free text\n",
    "tokens = tokenizer.tokenize(free_text)\n",
    "# Remove punctuation\n",
    "tokens_without_punctuation = [token for token in tokens if token.isalpha()]\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens_without_stopwords = [token for token in tokens_without_punctuation if token.lower() not in stop_words]\n",
    "# Lemmatize tokens\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens_without_stopwords]\n",
    "# Stem tokens\n",
    "stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
    "\n",
    "# Print the final tokens\n",
    "print(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503220d",
   "metadata": {},
   "source": [
    "# Performing Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42b4c16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [2019, ct, bauer, colleg, busi, graduat, magna...\n",
      "1      [nativ, english, teacher, epik, english, progr...\n",
      "2                    [aspir, human, resourc, profession]\n",
      "3                        [peopl, develop, coordin, ryan]\n",
      "4       [advisori, board, member, celal, bayar, univers]\n",
      "                             ...                        \n",
      "99     [aspir, human, resourc, manag, graduat, may, 2...\n",
      "100                [human, resourc, generalist, loparex]\n",
      "101                     [busi, intellig, analyt, travel]\n",
      "102                                [alway, set, success]\n",
      "103                    [director, administr, excel, log]\n",
      "Name: job_title, Length: 104, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Extract the desired attribute values\n",
    "attribute_values = read_data['job_title']\n",
    "print(attribute_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af61d3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Calculate Jaccard similarity with each attribute value\n",
    "jaccard_scores = []\n",
    "for value in attribute_values:\n",
    "    jaccard_sim = 1 - jaccard_distance(set(stemmed_tokens), set(value))\n",
    "    print(jaccard_scores.append((value, jaccard_sim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297a1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
